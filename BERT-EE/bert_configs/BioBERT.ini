[general]
seed=23
# ner or re  or  ner,re
tasks=ner,re

#CRITICAL, ERROR, WARNING,  INFO, DEBUG
log_level=INFO
multi_gpu = True
# train or predict
mode = predict
results_path = ./results

# use-specified folder name.  If not provided, default name is <task>_timestamp
results_folder = BioBERT

use_fine_tuned = True
# path of fine-tune model, applicable only if use_fine_tuned = True
fine_tuned_path = ../models/BioBERT_final/model/

# True if input text needs to be segmented into sentences.  False if input text has been segmented into sentences.
use_sent_segmentation=True
# True if using spacy tokenizer. False if tokenizing by space
use_spacy_tokenizer=True
spacy_model=en_core_web_lg

# this section is for named entity recognition (NER) task configuration
[ner]
# comma delimited list of ner labels included in training. If not provided, all annotated ner labels would be included.
labels =
scheme=IOB2

# folder path of annotated training data in BRAT .ann format
training_folder = 
# folder path of annotated validation data in BRAT .ann format
validation_folder = 
# folder path of text (.txt) files for prediction. Applicable if model=predict
prediction_folder = 

dropout=0.1
eval_mode=None

# this section is for relation extraction (RE) task configuration
[re]
# comma delimited list of re labels included in training. If not provided, all annotated re labels would be included.
labels =
# folder path of annotated training data in BRAT .ann format
training_folder = 
# folder path of annotated validation data in BRAT .ann format
validation_folder = 
# folder path of BRAT .ann data which should already contain NER labels.
# if none is provided, the predicted NER results would be used for RE prediction. Applicable if model=predict
prediction_folder =
dropout=0.1

# number of characters between two entities in a relation.
# If not set, the default is the median distance of all relations in labelled dataset
distance=
# limiting the number of no_relation as a percentage of total number of events
no_relation_ratio=0.5
num_workers=8
# number of sentences in which the relations would be considered.
max_sent_windows=2

# this section is for model configuration
[model]
max_seq_len=512
pretrained_model_name_or_path = dmis-lab/biobert-base-cased-v1.2
tokenizer_lower_case = False
batch=32
epochs=100
patience=10
grad_clipping=1.0
learning_rate=2e-5
weight_decay=0.0
adam_epsilon=1e-6
warmup_proportion =0.1
warmup_step=
#linear or ms or rop or exp or none
scheduler_type = none
learning_rate_decay_factor = 0.5
